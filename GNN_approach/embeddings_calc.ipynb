{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52266df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_vae_gnn_align.py\n",
    "\n",
    "Usage:\n",
    "    python train_vae_gnn_align.py --data_npz path/to/mock_sc_dataset.npz\n",
    "\n",
    "Expect the NPZ to contain:\n",
    " - ref_expr: (N_ref, G) raw counts or numeric matrix\n",
    " - ref_labels: (N_ref,) integer labels (optional, not used for embedding training)\n",
    " - query_expr: (N_query, G)\n",
    " - query_coords: (N_query, 2)\n",
    "\n",
    "Produces:\n",
    " - model checkpoints (vae_state.pt, gnn_state.pt)\n",
    " - final embeddings (final_embeddings.npz)\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d22afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Utilities & Losses\n",
    "# -------------------------\n",
    "def pairwise_distances(x, y=None):\n",
    "    \"\"\"Compute squared pairwise Euclidean distances between rows of x and rows of y (or x vs x).\"\"\"\n",
    "    if y is None:\n",
    "        y = x\n",
    "    x_norm = (x**2).sum(dim=1).view(-1,1)\n",
    "    y_norm = (y**2).sum(dim=1).view(1,-1)\n",
    "    dist = x_norm + y_norm - 2.0 * torch.mm(x, y.t())\n",
    "    return torch.clamp(dist, min=0.0)\n",
    "\n",
    "def gaussian_kernel_matrix(x, y, sigma):\n",
    "    dist = pairwise_distances(x, y)\n",
    "    return torch.exp(-dist / (2.0 * sigma**2))\n",
    "\n",
    "def mmd_rbf(x, y, sigmas=(1.0, 2.0, 4.0, 8.0)):\n",
    "    \"\"\"Maximum Mean Discrepancy with mixtures of RBF kernels.\"\"\"\n",
    "    Kxx = 0.0\n",
    "    Kyy = 0.0\n",
    "    Kxy = 0.0\n",
    "    for s in sigmas:\n",
    "        Kxx = Kxx + gaussian_kernel_matrix(x, x, s).mean()\n",
    "        Kyy = Kyy + gaussian_kernel_matrix(y, y, s).mean()\n",
    "        Kxy = Kxy + gaussian_kernel_matrix(x, y, s).mean()\n",
    "    return Kxx + Kyy - 2.0 * Kxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce360324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Models: Pt-1 VAE\n",
    "# -------------------------\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mu = nn.Linear(hidden_dim//2, latent_dim)\n",
    "        self.logvar = nn.Linear(hidden_dim//2, latent_dim)\n",
    "\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, input_dim),\n",
    "            # decoder output is real-valued (we'll use MSE on log1p data)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.enc(x)\n",
    "        return self.mu(h), self.logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.dec(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de74078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Models: Pt-1 GNN Encoder\n",
    "# -------------------------\n",
    "\n",
    "class GNNEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple 2-layer graph encoder using precomputed normalized adjacency A_norm:\n",
    "      h1 = relu(A_norm @ X @ W1 + b1)\n",
    "      z  = A_norm @ h1 @ W2 + b2\n",
    "    plus a small decoder from z -> reconstruct X.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        # linear transforms (we apply adjacency externally via matmul)\n",
    "        self.lin1 = nn.Linear(input_dim, hidden_dim, bias=True)\n",
    "        self.lin2 = nn.Linear(hidden_dim, latent_dim, bias=True)\n",
    "        # decoder: latent -> reconstruct expression\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, X, A_norm):\n",
    "        # X: (N, G); A_norm: (N, N) normalized adjacency (torch tensor)\n",
    "        H1 = torch.relu(A_norm @ self.lin1(X))  # (N, hidden)\n",
    "        Z  = A_norm @ self.lin2(H1)             # (N, latent)\n",
    "        recon = self.dec(Z)                     # (N, G)\n",
    "        return recon, Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a33275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Training function\n",
    "# -------------------------\n",
    "def train(\n",
    "    data_npz,\n",
    "    outdir=\"mock_sc_align\",\n",
    "    latent_dim=10,\n",
    "    batch_size=128,\n",
    "    epochs=50,\n",
    "    lr=1e-3,\n",
    "    k_nn=8,\n",
    "    alpha_vae=1.0,\n",
    "    alpha_gnn=1.0,\n",
    "    alpha_comp=1.0,\n",
    "    device=None\n",
    "):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    npz = np.load(data_npz, allow_pickle=True)\n",
    "    # required arrays\n",
    "    ref_expr = npz[\"ref_expr\"].astype(np.float32)   # (N_ref, G)\n",
    "    query_expr = npz[\"query_expr\"].astype(np.float32) # (N_query, G)\n",
    "    query_coords = npz[\"query_coords\"].astype(np.float32)  # (N_query, 2)\n",
    "    # optional\n",
    "    ref_labels = npz[\"ref_labels\"] if \"ref_labels\" in npz else None\n",
    "\n",
    "    # Preprocessing: log1p transform (common simple normalization)\n",
    "    ref_x = np.log1p(ref_expr)\n",
    "    query_x = np.log1p(query_expr)\n",
    "\n",
    "    N_ref, G = ref_x.shape\n",
    "    N_query = query_x.shape[0]\n",
    "\n",
    "    # Build normalized adjacency for query using kNN on coords\n",
    "    A = kneighbors_graph(query_coords, n_neighbors=k_nn, mode='connectivity', include_self=True).toarray().astype(float)\n",
    "    A = (A + A.T) / 2.0\n",
    "    A = A + np.eye(N_query)  # ensure self connections\n",
    "    deg = A.sum(axis=1)\n",
    "    D_inv_sqrt = np.diag(1.0 / np.sqrt(deg + 1e-8))\n",
    "    A_norm_np = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    A_norm = torch.tensor(A_norm_np, dtype=torch.float32, device=device)\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    ref_tensor = torch.tensor(ref_x, dtype=torch.float32, device=device)\n",
    "    query_tensor = torch.tensor(query_x, dtype=torch.float32, device=device)\n",
    "\n",
    "    # Dataloaders for reference (VAE uses minibatches)\n",
    "    ref_ds = TensorDataset(ref_tensor)\n",
    "    ref_loader = DataLoader(ref_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "    # instantiate models\n",
    "    vae = VAE(input_dim=G, latent_dim=latent_dim).to(device)\n",
    "    gnn = GNNEncoder(input_dim=G, latent_dim=latent_dim).to(device)\n",
    "\n",
    "    # optimizer over both models' parameters\n",
    "    opt = optim.Adam(list(vae.parameters()) + list(gnn.parameters()), lr=lr)\n",
    "\n",
    "    mse = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "    print(f\"Training on device: {device}; N_ref={N_ref}, N_query={N_query}, genes={G}\")\n",
    "    for ep in range(1, epochs+1):\n",
    "        vae.train(); gnn.train()\n",
    "        epoch_vae_loss = 0.0\n",
    "        epoch_gnn_loss = 0.0\n",
    "        epoch_comp_loss = 0.0\n",
    "        seen = 0\n",
    "\n",
    "        # Precompute full query forward for this epoch (we can update it inside loop as well;\n",
    "        # here we do full-batch forward each minibatch because GNN uses whole adjacency)\n",
    "        # This choice keeps GNN full-batch and VAE minibatched.\n",
    "        # You could instead update query forward after each optimizer step (done below).\n",
    "        for batch_idx, (batch_x,) in enumerate(ref_loader):\n",
    "            batch_size_curr = batch_x.size(0)\n",
    "            # VAE forward (on ref batch)\n",
    "            recon_b, mu_b, logvar_b, z_b = vae(batch_x)\n",
    "\n",
    "            # VAE losses: reconstruction (MSE) + KL\n",
    "            recon_loss_b = mse(recon_b, batch_x)\n",
    "            kl_b = -0.5 * torch.mean(1 + logvar_b - mu_b.pow(2) - logvar_b.exp())\n",
    "            vae_loss = recon_loss_b + kl_b\n",
    "\n",
    "            # GNN forward: full-batch on current query tensor (we use current model weights)\n",
    "            recon_q, z_q = gnn(query_tensor, A_norm)   # recon_q: (N_query, G), z_q: (N_query, latent)\n",
    "            gnn_recon_loss = mse(recon_q, query_tensor)\n",
    "\n",
    "            # Comparative loss: MMD between z_b (batch) and a random subset of z_q\n",
    "            # choose subset of query embeddings to match batch size (or smaller if query < batch)\n",
    "            q_sub_size = min(z_q.shape[0], z_b.shape[0])\n",
    "            # select indices randomly on CPU numpy for reproducibility (but can be torch)\n",
    "            q_idx = np.random.choice(z_q.shape[0], size=q_sub_size, replace=False)\n",
    "            z_q_sub = z_q[q_idx, :]\n",
    "\n",
    "            comp_loss = mmd_rbf(z_b, z_q_sub)\n",
    "\n",
    "            total_loss = alpha_vae * vae_loss + alpha_gnn * gnn_recon_loss + alpha_comp * comp_loss\n",
    "\n",
    "            opt.zero_grad()\n",
    "            total_loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            epoch_vae_loss += vae_loss.item() * batch_size_curr\n",
    "            epoch_gnn_loss += gnn_recon_loss.item() * batch_size_curr  # approximate bookkeeping\n",
    "            epoch_comp_loss += comp_loss.item() * batch_size_curr\n",
    "            seen += batch_size_curr\n",
    "\n",
    "        epoch_vae_loss /= seen\n",
    "        epoch_gnn_loss /= seen\n",
    "        epoch_comp_loss /= seen\n",
    "\n",
    "        # diagnostics: compute means and cosine similarity between full means of embeddings\n",
    "        with torch.no_grad():\n",
    "            vae.eval(); gnn.eval()\n",
    "            _, _, _, z_ref_full = vae(ref_tensor)     # (N_ref, latent)\n",
    "            _, z_query_full = gnn(query_tensor, A_norm)  # (N_query, latent)\n",
    "            mean_ref = z_ref_full.mean(dim=0)\n",
    "            mean_q = z_query_full.mean(dim=0)\n",
    "            mean_cos = nn.functional.cosine_similarity(mean_ref.unsqueeze(0), mean_q.unsqueeze(0)).item()\n",
    "            mean_euc = torch.norm(mean_ref - mean_q).item()\n",
    "\n",
    "        if ep % max(1, epochs//10) == 0 or ep == 1:\n",
    "            print(f\"[Epoch {ep:03d}/{epochs}] VAE_loss={epoch_vae_loss:.4f} | GNN_recon={epoch_gnn_loss:.4f} | MMD={epoch_comp_loss:.4f} | mean_cos={mean_cos:.4f} | mean_euc={mean_euc:.4f}\")\n",
    "\n",
    "    # Save models & embeddings\n",
    "    torch.save(vae.state_dict(), os.path.join(outdir, \"vae_state.pt\"))\n",
    "    torch.save(gnn.state_dict(), os.path.join(outdir, \"gnn_state.pt\"))\n",
    "\n",
    "    # final embeddings\n",
    "    with torch.no_grad():\n",
    "        vae.eval(); gnn.eval()\n",
    "        _, _, _, z_ref_final = vae(ref_tensor)\n",
    "        _, z_query_final = gnn(query_tensor, A_norm)\n",
    "\n",
    "    z_ref_final_np = z_ref_final.cpu().numpy()\n",
    "    z_query_final_np = z_query_final.cpu().numpy()\n",
    "    np.savez_compressed(os.path.join(outdir, \"final_embeddings.npz\"),\n",
    "                        z_ref=z_ref_final_np,\n",
    "                        z_query=z_query_final_np)\n",
    "    print(\"Saved models and embeddings to\", outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b6615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "## -------------------------\n",
    "## Loading the data set\n",
    "## -------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "data = np.load(\"mock_sc/mock_sc_dataset.npz\", allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94a4bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cpu; N_ref=1000, N_query=1000, genes=100\n",
      "[Epoch 001/50] VAE_loss=2.2319 | GNN_recon=2.6820 | MMD=1.2835 | mean_cos=0.9253 | mean_euc=0.5144\n",
      "[Epoch 005/50] VAE_loss=0.8314 | GNN_recon=0.5087 | MMD=0.3560 | mean_cos=0.9909 | mean_euc=0.4289\n",
      "[Epoch 010/50] VAE_loss=0.6218 | GNN_recon=0.3258 | MMD=0.3151 | mean_cos=0.9738 | mean_euc=0.4691\n",
      "[Epoch 015/50] VAE_loss=0.5213 | GNN_recon=0.2864 | MMD=0.3196 | mean_cos=0.9259 | mean_euc=0.3761\n",
      "[Epoch 020/50] VAE_loss=0.4921 | GNN_recon=0.2849 | MMD=0.3012 | mean_cos=0.7953 | mean_euc=0.3842\n",
      "[Epoch 025/50] VAE_loss=0.4838 | GNN_recon=0.2818 | MMD=0.2728 | mean_cos=0.6315 | mean_euc=0.2811\n",
      "[Epoch 030/50] VAE_loss=0.4752 | GNN_recon=0.2858 | MMD=0.2833 | mean_cos=0.4570 | mean_euc=0.3176\n",
      "[Epoch 035/50] VAE_loss=0.4762 | GNN_recon=0.2835 | MMD=0.2881 | mean_cos=0.0085 | mean_euc=0.3589\n",
      "[Epoch 040/50] VAE_loss=0.4713 | GNN_recon=0.2811 | MMD=0.2807 | mean_cos=0.2447 | mean_euc=0.1653\n",
      "[Epoch 045/50] VAE_loss=0.4659 | GNN_recon=0.2792 | MMD=0.2756 | mean_cos=0.2471 | mean_euc=0.2921\n",
      "[Epoch 050/50] VAE_loss=0.4595 | GNN_recon=0.2793 | MMD=0.2751 | mean_cos=-0.3805 | mean_euc=0.2119\n",
      "Saved models and embeddings to mock_sc_align\n"
     ]
    }
   ],
   "source": [
    "## -------------------------\n",
    "## Model training\n",
    "## -------------------------\n",
    "\n",
    "train(\"mock_sc/mock_sc_dataset.npz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
